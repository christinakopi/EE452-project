{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0LLc6ZvTUErf",
        "outputId": "e36c5de8-a30d-4286-b710-2d556a093484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric, mne\n",
            "Successfully installed mne-1.9.0 torch-geometric-2.6.1\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.4.26)\n",
            "Collecting seiz_eeg\n",
            "  Downloading seiz_eeg-0.4.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (8.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (2.2.2)\n",
            "Collecting pandera (from seiz_eeg)\n",
            "  Downloading pandera-0.23.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (18.1.0)\n",
            "Collecting pyEDFlib (from seiz_eeg)\n",
            "  Downloading pyedflib-0.1.40.tar.gz (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (1.15.2)\n",
            "Collecting omegaconf (from seiz_eeg)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (4.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (4.67.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->seiz_eeg)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf->seiz_eeg) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->seiz_eeg) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->seiz_eeg) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->seiz_eeg) (2025.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pandera->seiz_eeg) (24.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from pandera->seiz_eeg) (2.11.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.11/dist-packages (from pandera->seiz_eeg) (4.4.2)\n",
            "Collecting typing_inspect>=0.6.0 (from pandera->seiz_eeg)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect->seiz_eeg) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->seiz_eeg) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing_inspect>=0.6.0->pandera->seiz_eeg)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing_inspect>=0.6.0->pandera->seiz_eeg) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera->seiz_eeg) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera->seiz_eeg) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera->seiz_eeg) (0.4.0)\n",
            "Downloading seiz_eeg-0.4.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandera-0.23.1-py3-none-any.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.2/264.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, pyEDFlib\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=2b3cda4be39e9182ae65d5efe3b9f8072b571ca1248a4c3f1cd27b99cd815522\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for pyEDFlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyEDFlib: filename=pyedflib-0.1.40-cp311-cp311-linux_x86_64.whl size=2734979 sha256=7e73746630562670e2a8a73138a285b72858c2c9454ff50a09ae9ac9df26c210\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/df/d6/88ce619bde055ebffebae5380645802eca490817853b60b45b\n",
            "Successfully built antlr4-python3-runtime pyEDFlib\n",
            "Installing collected packages: antlr4-python3-runtime, pyEDFlib, omegaconf, mypy-extensions, typing_inspect, pandera, seiz_eeg\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 mypy-extensions-1.1.0 omegaconf-2.3.0 pandera-0.23.1 pyEDFlib-0.1.40 seiz_eeg-0.4.3 typing_inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "e48f26e534ac454d92e4e58ea189add0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install torch-geometric numpy scipy mne pandas scikit-learn\n",
        "!pip install mne\n",
        "!pip install seiz_eeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkiqF7RPXjNf",
        "outputId": "456608e3-d9fa-48a6-f322-0156278cac76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import mne\n",
        "\n",
        "from pathlib import Path\n",
        "from seiz_eeg.dataset import EEGDataset\n",
        "from torch_geometric.data import Data, Dataset as PyGDataset, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from scipy import signal\n",
        "from scipy.signal import welch"
      ],
      "metadata": {
        "id": "8wk3mu88QZ2v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading  \n",
        "Reads the pre‑windowed EEG metadata from parquet files and initializes `EEGDataset` instances, applying any time‑or frequency‑domain transforms.\n"
      ],
      "metadata": {
        "id": "vJqd-4HuayOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EEG parameters used later for the creation for the adjacency matric\n",
        "CH_NAMES   = [\n",
        "    'Fp1','Fp2','F7','F3','Fz','F4','F8',\n",
        "    'T3','C3','Cz','C4','T4','T5','P3',\n",
        "    'Pz','P4','T6','O1','O2'\n",
        "]\n",
        "\n",
        "# data Loading (using `EEGDataset`)\n",
        "# we read the pre-windowed segments from parquet, then wrap them into graphs\n",
        "\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/EPFL/NML\")\n",
        "\n",
        "# one row = one 12s window\n",
        "clips_tr = pd.read_parquet(DATA_ROOT / \"train\" / \"train\" / \"segments.parquet\")\n",
        "clips_te = pd.read_parquet(DATA_ROOT / \"test\"  / \"test\" / \"segments.parquet\")\n",
        "\n",
        "bp_filter = signal.butter(4, (0.5, 30), btype=\"bandpass\", output=\"sos\", fs=250)\n",
        "\n",
        "# filtering for the signals (given at example.ipynb)\n",
        "def time_filtering(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Filter signal in the time domain\"\"\"\n",
        "    return signal.sosfiltfilt(bp_filter, x, axis=0).copy()\n",
        "\n",
        "\n",
        "def fft_filtering(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Compute FFT and only keep\"\"\"\n",
        "    x = np.abs(np.fft.fft(x, axis=0))\n",
        "    x = np.log(np.where(x > 1e-8, x, 1e-8))\n",
        "\n",
        "    win_len = x.shape[0]\n",
        "    # Only frequencies b/w 0.5 and 30Hz\n",
        "    return x[int(0.5 * win_len // 250) : 30 * win_len // 250]\n",
        "\n",
        "# create the EEGDataset instances\n",
        "dataset_tr = EEGDataset(\n",
        "    clips_tr,\n",
        "    signals_root   = DATA_ROOT / \"train\" / \"train\",\n",
        "    signal_transform=fft_filtering,\n",
        "    prefetch=True\n",
        ")\n",
        "\n",
        "dataset_te = EEGDataset(\n",
        "    clips_te,\n",
        "    signals_root   = DATA_ROOT / \"test\" / \"test\",\n",
        "    signal_transform=fft_filtering,\n",
        "    prefetch=True,\n",
        "    return_id=True\n",
        ")\n",
        "\n",
        "print(f\"Loaded {len(dataset_tr):,} training windows, {len(dataset_te):,} test windows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdGJpADCtdWd",
        "outputId": "197a387b-0bf5-40a4-e279-122296dd269b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 12,993 training windows, 3,614 test windows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing & Graph Construction  \n",
        "Loads from the distances from the given distances_3d.csv file, pivots it into a 19×19 distance matrix, applies an RBF kernel to convert distances into similarities, and thresholds to build the adjacency matrix.\n"
      ],
      "metadata": {
        "id": "uxFaglFgbScc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_adjacency(dist_csv, ch_names, threshold_pct=75):\n",
        "    \"\"\"\n",
        "    Read the 3-columns [from,to,distance] of distances_3d.csv and build a symmetric adjacency:\n",
        "    \"\"\"\n",
        "    # read and pivot\n",
        "    df = pd.read_csv(dist_csv)\n",
        "    dmat = df.pivot(index='from', columns='to', values='distance')\n",
        "    dmat = dmat.reindex(index=ch_names, columns=ch_names)\n",
        "    dist = dmat.values.astype(float)\n",
        "\n",
        "    # zero the diagonal\n",
        "    np.fill_diagonal(dist, 0.0)\n",
        "\n",
        "    # mirror known entries to get symmetric matrix\n",
        "    mask = np.isnan(dist)\n",
        "    dist[mask] = dist.T[mask]\n",
        "\n",
        "    # fill any remaining NaNs with the max so that missing pairs become “very far apart”\n",
        "    max_dist = np.nanmax(dist)\n",
        "    dist[np.isnan(dist)] = max_dist\n",
        "\n",
        "    # build RBF weights\n",
        "    sigma = dist.mean()\n",
        "    W = np.exp(-dist**2 / (2 * sigma**2))\n",
        "\n",
        "    # sparsify by zeroing out the weakest edges\n",
        "    cutoff = np.percentile(W, threshold_pct)\n",
        "    W[W < cutoff] = 0.0\n",
        "\n",
        "    # zero the diagonal again\n",
        "    np.fill_diagonal(W, 0.0)\n",
        "\n",
        "    return W\n",
        "\n",
        "distances_csv = DATA_ROOT / \"distances_3d.csv\"\n",
        "A = load_adjacency(distances_csv, CH_NAMES, threshold_pct=30) # changed the threshold to a lower value otherwise I was getting many 0s (only very strong connections were considered)\n",
        "print(\"Adjacency shape:\", A.shape, \"  density:\", (A>0).mean())\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3cTOXT7kDGg",
        "outputId": "aad4328e-85cf-46aa-f2d4-960c6b292c58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjacency shape: (19, 19)   density: 0.9473684210526315\n",
            "[[0.         0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.         0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.43858603 0.         0.93576703 0.43858603 0.64896094\n",
            "  0.58308472 0.92430892 0.83832074 0.43858603 0.52317844 0.47450356\n",
            "  0.75218863 0.67583695 0.43858603 0.46869762 0.4385897  0.58304998\n",
            "  0.47448915]\n",
            " [0.43858603 0.43858603 0.93576703 0.         0.43858603 0.78010715\n",
            "  0.64896094 0.83036187 0.89836861 0.43858603 0.65241855 0.52819134\n",
            "  0.67583695 0.68944871 0.43858603 0.53784387 0.46869762 0.5458095\n",
            "  0.47460245]\n",
            " [0.43858603 0.43858603 0.43858603 0.43858603 0.         0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.43858603 0.64896094 0.78010715 0.43858603 0.\n",
            "  0.93576703 0.52819134 0.65241855 0.43858603 0.89836861 0.83036187\n",
            "  0.46869762 0.53784387 0.43858603 0.68944871 0.67583695 0.47460245\n",
            "  0.5458095 ]\n",
            " [0.43858603 0.43858603 0.58308472 0.64896094 0.43858603 0.93576703\n",
            "  0.         0.47450356 0.52317844 0.43858603 0.83832074 0.92430892\n",
            "  0.4385897  0.46869762 0.43858603 0.67583695 0.75218863 0.47448915\n",
            "  0.58304998]\n",
            " [0.43858603 0.43858603 0.92430892 0.83036187 0.43858603 0.52819134\n",
            "  0.47450356 0.         0.88629978 0.43858603 0.49485457 0.43858603\n",
            "  0.92430892 0.83036187 0.43858603 0.52819134 0.47450356 0.75218292\n",
            "  0.58306692]\n",
            " [0.43858603 0.43858603 0.83832074 0.89836861 0.43858603 0.65241855\n",
            "  0.52317844 0.88629978 0.         0.43858603 0.66226352 0.49485457\n",
            "  0.83832074 0.89836861 0.43858603 0.65241855 0.52317844 0.72464796\n",
            "  0.60522691]\n",
            " [0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.         0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.43858603 0.52317844 0.65241855 0.43858603 0.89836861\n",
            "  0.83832074 0.49485457 0.66226352 0.43858603 0.         0.88629978\n",
            "  0.52317844 0.65241855 0.43858603 0.89836861 0.83832074 0.60522691\n",
            "  0.72464796]\n",
            " [0.43858603 0.43858603 0.47450356 0.52819134 0.43858603 0.83036187\n",
            "  0.92430892 0.43858603 0.49485457 0.43858603 0.88629978 0.\n",
            "  0.47450356 0.52819134 0.43858603 0.83036187 0.92430892 0.58306692\n",
            "  0.75218292]\n",
            " [0.43858603 0.43858603 0.75218863 0.67583695 0.43858603 0.46869762\n",
            "  0.4385897  0.92430892 0.83832074 0.43858603 0.52317844 0.47450356\n",
            "  0.         0.93576703 0.43858603 0.64896094 0.58308472 0.92430948\n",
            "  0.75220793]\n",
            " [0.43858603 0.43858603 0.67583695 0.68944871 0.43858603 0.53784387\n",
            "  0.46869762 0.83036187 0.89836861 0.43858603 0.65241855 0.52819134\n",
            "  0.93576703 0.         0.43858603 0.78010715 0.64896094 0.9240932\n",
            "  0.80353473]\n",
            " [0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.         0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.43858603 0.46869762 0.53784387 0.43858603 0.68944871\n",
            "  0.67583695 0.52819134 0.65241855 0.43858603 0.89836861 0.83036187\n",
            "  0.64896094 0.78010715 0.43858603 0.         0.93576703 0.80353473\n",
            "  0.9240932 ]\n",
            " [0.43858603 0.43858603 0.4385897  0.46869762 0.43858603 0.67583695\n",
            "  0.75218863 0.47450356 0.52317844 0.43858603 0.83832074 0.92430892\n",
            "  0.58308472 0.64896094 0.43858603 0.93576703 0.         0.75220793\n",
            "  0.92430948]\n",
            " [0.43858603 0.43858603 0.58304998 0.5458095  0.43858603 0.47460245\n",
            "  0.47448915 0.75218292 0.72464796 0.43858603 0.60522691 0.58306692\n",
            "  0.92430948 0.9240932  0.43858603 0.80353473 0.75220793 0.\n",
            "  0.92432145]\n",
            " [0.43858603 0.43858603 0.47448915 0.47460245 0.43858603 0.5458095\n",
            "  0.58304998 0.58306692 0.60522691 0.43858603 0.72464796 0.75218292\n",
            "  0.75220793 0.80353473 0.43858603 0.9240932  0.92430948 0.92432145\n",
            "  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyG Dataset Wrapper  \n",
        "Defines `GraphFromEEG`, which takes each transformed EEG window, computes per‑channel features (mean, variance, peak-to-peak, zero-crossing rate etc.), and uses the fixed graph topology (edges + weights) to produce `torch_geometric.data.Data` objects.\n"
      ],
      "metadata": {
        "id": "XIBYRcUsbmeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size    = 32\n",
        "epochs        = 20\n",
        "learning_rate = 1e-3\n",
        "\n",
        "SFREQ = 250  # Hz, matches the dataset’s sampling rate\n",
        "\n",
        "class GraphFromEEG(PyGDataset):\n",
        "    def __init__(self, eeg_ds, adj, is_test=False):\n",
        "        super().__init__()\n",
        "        self.eeg_ds   = eeg_ds\n",
        "        self.is_test  = is_test\n",
        "\n",
        "        rows, cols        = np.nonzero(adj > 0)\n",
        "        self.edge_index   = torch.tensor([rows, cols], dtype=torch.long)\n",
        "        self.edge_weight  = torch.tensor(adj[rows, cols], dtype=torch.float)\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.eeg_ds)\n",
        "\n",
        "    def get(self, idx):\n",
        "        arr, meta = self.eeg_ds[idx]\n",
        "        if self.is_test:\n",
        "            signal, sid = arr, meta\n",
        "            label = None\n",
        "        else:\n",
        "            signal, label = arr, meta\n",
        "            sid = None\n",
        "\n",
        "        # signal: (n_time_bins, n_channels)\n",
        "        # Compute 9 features per channel\n",
        "\n",
        "        # 1) mean\n",
        "        mean_ = signal.mean(axis=0)\n",
        "\n",
        "        # 2) variance\n",
        "        var_  = signal.var(axis=0)\n",
        "\n",
        "        # 3) peak-to-peak\n",
        "        ptp_  = np.ptp(signal, axis=0)\n",
        "\n",
        "        # 4) zero-crossing rate\n",
        "        zcr_  = np.mean(np.diff(np.sign(signal), axis=0) != 0, axis=0)\n",
        "\n",
        "        # 5) PSD via Welch\n",
        "        freqs, psd = welch(signal, fs=SFREQ, axis=0)\n",
        "\n",
        "        def bandpower(pxx, freqs, fmin, fmax):\n",
        "            mask = (freqs >= fmin) & (freqs <= fmax)\n",
        "            return pxx[mask].mean(axis=0)\n",
        "\n",
        "        # 6–10) Bandpower in δ (1–4), θ (4–8), α (8–12), β (12–30), γ (30–45)\n",
        "        delta = bandpower(psd, freqs, 1, 4)\n",
        "        theta = bandpower(psd, freqs, 4, 8)\n",
        "        alpha = bandpower(psd, freqs, 8, 12)\n",
        "        beta  = bandpower(psd, freqs, 12, 30)\n",
        "        gamma = bandpower(psd, freqs, 30, 45)\n",
        "\n",
        "        # stack into (n_channels, 9) feature matrix\n",
        "        features = np.stack([mean_, var_, ptp_, zcr_,\n",
        "                             delta, theta, alpha, beta, gamma], axis=1)\n",
        "\n",
        "        x = torch.tensor(features, dtype=torch.float)\n",
        "\n",
        "        y = torch.tensor([label], dtype=torch.long) if label is not None else None\n",
        "\n",
        "        data = Data(x=x,\n",
        "                    edge_index=self.edge_index,\n",
        "                    edge_attr=self.edge_weight,\n",
        "                    y=y)\n",
        "\n",
        "        # keep index for later id lookup\n",
        "        data.idx = torch.tensor([idx], dtype=torch.long)\n",
        "        return data\n",
        "\n",
        "graph_tr = GraphFromEEG(dataset_tr, A, is_test=False)\n",
        "graph_te = GraphFromEEG(dataset_te, A, is_test=True)\n",
        "\n",
        "loader_tr = DataLoader(graph_tr, batch_size=batch_size, shuffle=True)\n",
        "loader_te = DataLoader(graph_te, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Graphified train size: {len(graph_tr)}, test size: {len(graph_te)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHKdZ4aveusj",
        "outputId": "26fef313-75bd-4d11-a4d1-061b5017553c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graphified train size: 12993, test size: 3614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader with balancing\n",
        "Instantiate `DataLoader` over our training graph dataset—using a `WeightedRandomSampler` to balance seizure vs. non‑seizure windows during training\n"
      ],
      "metadata": {
        "id": "tNqVVvubcXva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Balance the labels by giving more weight to the minority class\n",
        "# Difference in the number of samples per class: [10476, 2517]\n",
        "\n",
        "train_labels = [data.y.item() for data in graph_tr]\n",
        "counts = np.bincount(train_labels)\n",
        "weights = 1.0 / counts    # gives more weight to the minority class\n",
        "\n",
        "# sample‐wise weight vector\n",
        "sample_weights = np.array([weights[l] for l in train_labels])\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# rebuild the train loader\n",
        "loader_tr = DataLoader(\n",
        "    graph_tr,\n",
        "    batch_size=batch_size,\n",
        "    sampler=sampler,\n",
        "    num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "yVRk0FJTsEwx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition & Training\n",
        "Builds the GCN model (`EEG_GCN`) with two graph‐convolution layers followed by global mean pooling and a linear layer for binary classification also trains the GCN over 20 epochs using cross‑entropy and prints train loss and accuracy."
      ],
      "metadata": {
        "id": "zfe9wvzCcoA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model & Training\n",
        "\n",
        "class EEG_GCN(torch.nn.Module):\n",
        "    def __init__(self, in_feats=1, hid_feats=64, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_feats, hid_feats)\n",
        "        self.conv2 = GCNConv(hid_feats, hid_feats)\n",
        "        self.lin   = torch.nn.Linear(hid_feats, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, ei, ew, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        x = F.relu(self.conv1(x, ei, edge_weight=ew))\n",
        "        x = F.relu(self.conv2(x, ei, edge_weight=ew))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return self.lin(x)\n",
        "\n",
        "def train_epoch(model, loader, opt, device):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        opt.zero_grad()\n",
        "        loss = F.cross_entropy(model(data), data.y.view(-1))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total += loss.item() * data.num_graphs\n",
        "    return total / len(loader.dataset)\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            preds = model(data).argmax(dim=1)\n",
        "            correct += (preds == data.y.view(-1)).sum().item()\n",
        "            total   += data.num_graphs\n",
        "    return correct / total\n",
        "\n",
        "# Train & Validation\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model     = EEG_GCN(in_feats = 9).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    loss   = train_epoch(model, loader_tr, optimizer, device)\n",
        "    acc    = evaluate(model, loader_tr, device)\n",
        "    print(f\"Epoch {epoch:02d}: Train Loss = {loss:.4f}, Train Acc = {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN_fTvPVs4Du",
        "outputId": "bb77cdbd-fc58-47b2-b73c-c3b33187cb6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: Train Loss = 0.6416, Train Acc = 0.6496\n",
            "Epoch 02: Train Loss = 0.6250, Train Acc = 0.6128\n",
            "Epoch 03: Train Loss = 0.6131, Train Acc = 0.6596\n",
            "Epoch 04: Train Loss = 0.6073, Train Acc = 0.6550\n",
            "Epoch 05: Train Loss = 0.5965, Train Acc = 0.6870\n",
            "Epoch 06: Train Loss = 0.5932, Train Acc = 0.6699\n",
            "Epoch 07: Train Loss = 0.5811, Train Acc = 0.7021\n",
            "Epoch 08: Train Loss = 0.5807, Train Acc = 0.6961\n",
            "Epoch 09: Train Loss = 0.5751, Train Acc = 0.6744\n",
            "Epoch 10: Train Loss = 0.5744, Train Acc = 0.7161\n",
            "Epoch 11: Train Loss = 0.5663, Train Acc = 0.7130\n",
            "Epoch 12: Train Loss = 0.5666, Train Acc = 0.7156\n",
            "Epoch 13: Train Loss = 0.5513, Train Acc = 0.6859\n",
            "Epoch 14: Train Loss = 0.5549, Train Acc = 0.6987\n",
            "Epoch 15: Train Loss = 0.5583, Train Acc = 0.7016\n",
            "Epoch 16: Train Loss = 0.5558, Train Acc = 0.7125\n",
            "Epoch 17: Train Loss = 0.5525, Train Acc = 0.7145\n",
            "Epoch 18: Train Loss = 0.5530, Train Acc = 0.7288\n",
            "Epoch 19: Train Loss = 0.5539, Train Acc = 0.7213\n",
            "Epoch 20: Train Loss = 0.5484, Train Acc = 0.7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Prediction & Submission  \n",
        "Run inference on the test loader, map each prediction back to the original window IDs and write out a Kaggle‐compatible CSV of `id,label` rows.\n"
      ],
      "metadata": {
        "id": "dQbJShrQcyO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Test & Submission\n",
        "\n",
        "model.eval()\n",
        "all_idxs, all_preds = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in loader_te:\n",
        "        # batch.idx is a tensor of shape [batch_size] giving the original idx\n",
        "        all_idxs.extend(batch.idx.cpu().tolist())\n",
        "        batch = batch.to(device)\n",
        "        logits = model(batch)\n",
        "        preds = logits.argmax(dim=1).cpu().tolist()\n",
        "        all_preds.extend(preds)\n",
        "\n",
        "all_ids = clips_te.index.tolist()\n",
        "\n",
        "# check\n",
        "assert len(all_ids) == len(all_preds)\n",
        "\n",
        "# write submission\n",
        "submission = pd.DataFrame({'id': all_ids, 'label': all_preds})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(f\"Saved submission.csv with {len(submission)} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F78dsCARzdkP",
        "outputId": "1263a66d-23d5-42e8-a606-1e3696ff2e85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv with 3614 rows\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}