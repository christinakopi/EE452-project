{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LLc6ZvTUErf",
        "outputId": "36902b94-174b-4b79-9068-a918314c3d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.4.26)\n",
            "Requirement already satisfied: seiz_eeg in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (8.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (2.2.2)\n",
            "Requirement already satisfied: pandera in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (0.23.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (18.1.0)\n",
            "Requirement already satisfied: pyEDFlib in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (0.1.40)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (1.15.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (2.3.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (4.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from seiz_eeg) (4.67.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->seiz_eeg) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf->seiz_eeg) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->seiz_eeg) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->seiz_eeg) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->seiz_eeg) (2025.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pandera->seiz_eeg) (24.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from pandera->seiz_eeg) (2.11.4)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.11/dist-packages (from pandera->seiz_eeg) (4.4.2)\n",
            "Requirement already satisfied: typing_inspect>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pandera->seiz_eeg) (0.9.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect->seiz_eeg) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->seiz_eeg) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing_inspect>=0.6.0->pandera->seiz_eeg) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing_inspect>=0.6.0->pandera->seiz_eeg) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera->seiz_eeg) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera->seiz_eeg) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera->seiz_eeg) (0.4.0)\n",
            "Collecting PyWavelets\n",
            "  Using cached pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n",
            "Using cached pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Installing collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install torch-geometric numpy scipy mne pandas scikit-learn\n",
        "!pip install mne\n",
        "!pip install seiz_eeg\n",
        "!pip install PyWavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkiqF7RPXjNf",
        "outputId": "38bb920f-2c42-4925-a6e1-825a84c25c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8wk3mu88QZ2v"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from scipy import signal\n",
        "from scipy.signal import welch\n",
        "import pywt\n",
        "from seiz_eeg.dataset import EEGDataset\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.data import Dataset as PyGDataset\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJqd-4HuayOR"
      },
      "source": [
        "### Data Loading  \n",
        "Reads the pre‑windowed EEG metadata from parquet files and initializes `EEGDataset` instances, applying any time‑or frequency‑domain transforms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdGJpADCtdWd",
        "outputId": "ea86d843-6f9e-4d00-a1b9-0fcf33528026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 12,993 training windows, 3,614 test windows.\n"
          ]
        }
      ],
      "source": [
        "# EEG parameters used later for the creation for the adjacency matric\n",
        "CH_NAMES = [\n",
        "    \"Fp1\",\n",
        "    \"Fp2\",\n",
        "    \"F7\",\n",
        "    \"F3\",\n",
        "    \"Fz\",\n",
        "    \"F4\",\n",
        "    \"F8\",\n",
        "    \"T3\",\n",
        "    \"C3\",\n",
        "    \"Cz\",\n",
        "    \"C4\",\n",
        "    \"T4\",\n",
        "    \"T5\",\n",
        "    \"P3\",\n",
        "    \"Pz\",\n",
        "    \"P4\",\n",
        "    \"T6\",\n",
        "    \"O1\",\n",
        "    \"O2\",\n",
        "]\n",
        "\n",
        "# data Loading (using `EEGDataset`)\n",
        "# we read the pre-windowed segments from parquet, then wrap them into graphs\n",
        "\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/EPFL/NML/epfl-network-machine-learning-2025\")\n",
        "\n",
        "# one row = one 12s window\n",
        "clips_tr = pd.read_parquet(DATA_ROOT / \"train\" / \"train\" / \"segments.parquet\")\n",
        "clips_te = pd.read_parquet(DATA_ROOT / \"test\" / \"test\" / \"segments.parquet\")\n",
        "\n",
        "bp_filter = signal.butter(4, (0.5, 30), btype=\"bandpass\", output=\"sos\", fs=250)\n",
        "\n",
        "\n",
        "# filtering for the signals (given at example.ipynb)\n",
        "def time_filtering(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Filter signal in the time domain\"\"\"\n",
        "    return signal.sosfiltfilt(bp_filter, x, axis=0).copy()\n",
        "\n",
        "\n",
        "def fft_filtering(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Compute FFT and only keep\"\"\"\n",
        "    x = np.abs(np.fft.fft(x, axis=0))\n",
        "    x = np.log(np.where(x > 1e-8, x, 1e-8))\n",
        "\n",
        "    win_len = x.shape[0]\n",
        "    # Only frequencies b/w 0.5 and 30Hz\n",
        "    return x[int(0.5 * win_len // 250) : 30 * win_len // 250]\n",
        "\n",
        "\n",
        "def stft_filtering(x: np.ndarray) -> np.ndarray:\n",
        "    nperseg = x.shape[0]\n",
        "    channel_shapes = x.shape[1]\n",
        "    f, t, Zxx = signal.stft(x, fs=250, axis=0, nperseg=nperseg, noverlap=0)\n",
        "\n",
        "    Zxx = np.abs(Zxx.reshape(-1, channel_shapes))\n",
        "    mag = np.log(np.where(Zxx > 1e-8, Zxx, 1e-8))\n",
        "\n",
        "    win_len = mag.shape[0]\n",
        "    # Only frequencies b/w 0.5 and 30Hz\n",
        "    return mag[int(0.5 * win_len // 250) : 30 * win_len // 250]\n",
        "\n",
        "\n",
        "def psd_filtering(x: np.ndarray) -> np.ndarray:\n",
        "    nperseg = x.shape[0]\n",
        "    f, Pxx = signal.welch(x, fs=250, axis=0, nperseg=nperseg, noverlap=0)\n",
        "    Pxx = np.abs(Pxx)\n",
        "    mag = np.log(np.where(Pxx > 1e-8, Pxx, 1e-8))\n",
        "\n",
        "    win_len = mag.shape[0]\n",
        "    # Only frequencies b/w 0.5 and 30Hz\n",
        "    return mag[int(0.5 * win_len // 250) : 30 * win_len // 250]\n",
        "\n",
        "\n",
        "def wt_filtering(x: np.ndarray,  wavelet='db4', threshold=0)-> np.ndarray :\n",
        "    denoised = np.zeros_like(x)\n",
        "    orig_len, n_signals = x.shape\n",
        "\n",
        "    for i in range(n_signals):\n",
        "        coeffs = pywt.wavedec(x[:, i], wavelet, level=1)\n",
        "\n",
        "        for j in range(1, len(coeffs)):\n",
        "            K = np.round(threshold * len(coeffs[j])).astype(int)\n",
        "            if K < len(coeffs[j]):\n",
        "                coeffs[j][K:] = 0\n",
        "\n",
        "        denoised_ = pywt.waverec(coeffs, wavelet)\n",
        "\n",
        "        # handle length mismatch\n",
        "        if len(denoised_) > orig_len:\n",
        "            denoised[:, i] = denoised_[:orig_len]\n",
        "        elif len(denoised_) < orig_len:\n",
        "            denoised[:, i] = np.pad(denoised_, (0, orig_len - len(denoised_)), 'constant')\n",
        "        else:\n",
        "            denoised[:, i] = denoised_\n",
        "\n",
        "    return denoised\n",
        "\n",
        "# create the EEGDataset instances\n",
        "dataset_tr = EEGDataset(\n",
        "    clips_tr,\n",
        "    signals_root=DATA_ROOT / \"train\" / \"train\",\n",
        "    signal_transform=wt_filtering,\n",
        "    prefetch=True,\n",
        ")\n",
        "\n",
        "dataset_te = EEGDataset(\n",
        "    clips_te,\n",
        "    signals_root=DATA_ROOT / \"test\" / \"test\",\n",
        "    signal_transform=wt_filtering,\n",
        "    prefetch=True,\n",
        "    return_id=True,\n",
        ")\n",
        "\n",
        "print(f\"Loaded {len(dataset_tr):,} training windows, {len(dataset_te):,} test windows.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxFaglFgbScc"
      },
      "source": [
        "### Preprocessing & Graph Construction  \n",
        "Loads from the distances from the given distances_3d.csv file, pivots it into a 19×19 distance matrix, applies an RBF kernel to convert distances into similarities, and thresholds to build the adjacency matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3cTOXT7kDGg",
        "outputId": "573c91ad-f399-4ed6-cd37-9ace6d8bfc44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjacency shape: (19, 19)   density: 0.9473684210526315\n",
            "[[0.         0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.         0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.43858603 0.         0.93576703 0.43858603 0.64896094\n",
            "  0.58308472 0.92430892 0.83832074 0.43858603 0.52317844 0.47450356\n",
            "  0.75218863 0.67583695 0.43858603 0.46869762 0.4385897  0.58304998\n",
            "  0.47448915]\n",
            " [0.43858603 0.43858603 0.93576703 0.         0.43858603 0.78010715\n",
            "  0.64896094 0.83036187 0.89836861 0.43858603 0.65241855 0.52819134\n",
            "  0.67583695 0.68944871 0.43858603 0.53784387 0.46869762 0.5458095\n",
            "  0.47460245]\n",
            " [0.43858603 0.43858603 0.43858603 0.43858603 0.         0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.43858603 0.64896094 0.78010715 0.43858603 0.\n",
            "  0.93576703 0.52819134 0.65241855 0.43858603 0.89836861 0.83036187\n",
            "  0.46869762 0.53784387 0.43858603 0.68944871 0.67583695 0.47460245\n",
            "  0.5458095 ]\n",
            " [0.43858603 0.43858603 0.58308472 0.64896094 0.43858603 0.93576703\n",
            "  0.         0.47450356 0.52317844 0.43858603 0.83832074 0.92430892\n",
            "  0.4385897  0.46869762 0.43858603 0.67583695 0.75218863 0.47448915\n",
            "  0.58304998]\n",
            " [0.43858603 0.43858603 0.92430892 0.83036187 0.43858603 0.52819134\n",
            "  0.47450356 0.         0.88629978 0.43858603 0.49485457 0.43858603\n",
            "  0.92430892 0.83036187 0.43858603 0.52819134 0.47450356 0.75218292\n",
            "  0.58306692]\n",
            " [0.43858603 0.43858603 0.83832074 0.89836861 0.43858603 0.65241855\n",
            "  0.52317844 0.88629978 0.         0.43858603 0.66226352 0.49485457\n",
            "  0.83832074 0.89836861 0.43858603 0.65241855 0.52317844 0.72464796\n",
            "  0.60522691]\n",
            " [0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.         0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.43858603 0.52317844 0.65241855 0.43858603 0.89836861\n",
            "  0.83832074 0.49485457 0.66226352 0.43858603 0.         0.88629978\n",
            "  0.52317844 0.65241855 0.43858603 0.89836861 0.83832074 0.60522691\n",
            "  0.72464796]\n",
            " [0.43858603 0.43858603 0.47450356 0.52819134 0.43858603 0.83036187\n",
            "  0.92430892 0.43858603 0.49485457 0.43858603 0.88629978 0.\n",
            "  0.47450356 0.52819134 0.43858603 0.83036187 0.92430892 0.58306692\n",
            "  0.75218292]\n",
            " [0.43858603 0.43858603 0.75218863 0.67583695 0.43858603 0.46869762\n",
            "  0.4385897  0.92430892 0.83832074 0.43858603 0.52317844 0.47450356\n",
            "  0.         0.93576703 0.43858603 0.64896094 0.58308472 0.92430948\n",
            "  0.75220793]\n",
            " [0.43858603 0.43858603 0.67583695 0.68944871 0.43858603 0.53784387\n",
            "  0.46869762 0.83036187 0.89836861 0.43858603 0.65241855 0.52819134\n",
            "  0.93576703 0.         0.43858603 0.78010715 0.64896094 0.9240932\n",
            "  0.80353473]\n",
            " [0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.43858603 0.43858603 0.43858603 0.43858603\n",
            "  0.43858603 0.43858603 0.         0.43858603 0.43858603 0.43858603\n",
            "  0.43858603]\n",
            " [0.43858603 0.43858603 0.46869762 0.53784387 0.43858603 0.68944871\n",
            "  0.67583695 0.52819134 0.65241855 0.43858603 0.89836861 0.83036187\n",
            "  0.64896094 0.78010715 0.43858603 0.         0.93576703 0.80353473\n",
            "  0.9240932 ]\n",
            " [0.43858603 0.43858603 0.4385897  0.46869762 0.43858603 0.67583695\n",
            "  0.75218863 0.47450356 0.52317844 0.43858603 0.83832074 0.92430892\n",
            "  0.58308472 0.64896094 0.43858603 0.93576703 0.         0.75220793\n",
            "  0.92430948]\n",
            " [0.43858603 0.43858603 0.58304998 0.5458095  0.43858603 0.47460245\n",
            "  0.47448915 0.75218292 0.72464796 0.43858603 0.60522691 0.58306692\n",
            "  0.92430948 0.9240932  0.43858603 0.80353473 0.75220793 0.\n",
            "  0.92432145]\n",
            " [0.43858603 0.43858603 0.47448915 0.47460245 0.43858603 0.5458095\n",
            "  0.58304998 0.58306692 0.60522691 0.43858603 0.72464796 0.75218292\n",
            "  0.75220793 0.80353473 0.43858603 0.9240932  0.92430948 0.92432145\n",
            "  0.        ]]\n"
          ]
        }
      ],
      "source": [
        "def load_adjacency(dist_csv, ch_names, threshold_pct=75):\n",
        "    \"\"\"Read the 3-columns [from,to,distance] of distances_3d.csv and build a symmetric adjacency:\"\"\"\n",
        "    # read and pivot\n",
        "    df = pd.read_csv(dist_csv)\n",
        "    dmat = df.pivot(index=\"from\", columns=\"to\", values=\"distance\")\n",
        "    dmat = dmat.reindex(index=ch_names, columns=ch_names)\n",
        "    dist = dmat.values.astype(float)\n",
        "\n",
        "    # zero the diagonal\n",
        "    np.fill_diagonal(dist, 0.0)\n",
        "\n",
        "    # mirror known entries to get symmetric matrix\n",
        "    mask = np.isnan(dist)\n",
        "    dist[mask] = dist.T[mask]\n",
        "\n",
        "    # fill any remaining NaNs with the max so that missing pairs become “very far apart”\n",
        "    max_dist = np.nanmax(dist)\n",
        "    dist[np.isnan(dist)] = max_dist\n",
        "\n",
        "    # build RBF weights\n",
        "    sigma = dist.mean()\n",
        "    W = np.exp(-(dist**2) / (2 * sigma**2))\n",
        "\n",
        "    # sparsify by zeroing out the weakest edges\n",
        "    cutoff = np.percentile(W, threshold_pct)\n",
        "    W[W < cutoff] = 0.0\n",
        "\n",
        "    # zero the diagonal again\n",
        "    np.fill_diagonal(W, 0.0)\n",
        "\n",
        "    return W\n",
        "\n",
        "\n",
        "distances_csv = DATA_ROOT / \"distances_3d.csv\"\n",
        "A = load_adjacency(\n",
        "    distances_csv, CH_NAMES, threshold_pct=30\n",
        ")  # changed the threshold to a lower value otherwise I was getting many 0s (only very strong connections were considered)\n",
        "print(\"Adjacency shape:\", A.shape, \"  density:\", (A > 0).mean())\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIBYRcUsbmeA"
      },
      "source": [
        "### PyG Dataset Wrapper  \n",
        "Defines `GraphFromEEG`, which takes each transformed EEG window, computes per‑channel features (mean, variance, peak-to-peak, zero-crossing rate etc.), and uses the fixed graph topology (edges + weights) to produce `torch_geometric.data.Data` objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHKdZ4aveusj",
        "outputId": "a18f819f-e512-435e-f989-617ea2f7d252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([96000, 19])\n",
            "Graphified train size: 12993, test size: 3614\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "learning_rate = 1e-3\n",
        "\n",
        "SFREQ = 250  # Hz, matches the dataset’s sampling rate\n",
        "\n",
        "class GraphFromEEG(PyGDataset):\n",
        "    def __init__(self, eeg_ds, adj, is_test=False):\n",
        "        super().__init__()\n",
        "        self.eeg_ds = eeg_ds\n",
        "        self.is_test = is_test\n",
        "\n",
        "        rows, cols = np.nonzero(adj > 0)\n",
        "        self.edge_index = torch.tensor([rows, cols], dtype=torch.long)\n",
        "        self.edge_weight = torch.tensor(adj[rows, cols], dtype=torch.float)\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.eeg_ds)\n",
        "\n",
        "    def extract_handcrafted_signal_features(self, signal):\n",
        "        # 1) mean\n",
        "        mean_ = signal.mean(axis=0)\n",
        "\n",
        "        # 2) variance\n",
        "        var_ = signal.var(axis=0)\n",
        "\n",
        "        # 3) peak-to-peak\n",
        "        ptp_ = np.ptp(signal, axis=0)\n",
        "\n",
        "        # 4) zero-crossing rate\n",
        "        zcr_ = np.mean(np.diff(np.sign(signal), axis=0) != 0, axis=0)\n",
        "\n",
        "        # 5) PSD via Welch\n",
        "        freqs, psd = welch(signal, fs=SFREQ, axis=0)\n",
        "\n",
        "        def bandpower(pxx, freqs, fmin, fmax):\n",
        "            mask = (freqs >= fmin) & (freqs <= fmax)\n",
        "            return pxx[mask].mean(axis=0)\n",
        "\n",
        "        # 6–10) Bandpower in δ (1–4), θ (4–8), α (8–12), β (12–30), γ (30–45)\n",
        "        delta = bandpower(psd, freqs, 1, 4)\n",
        "        theta = bandpower(psd, freqs, 4, 8)\n",
        "        alpha = bandpower(psd, freqs, 8, 12)\n",
        "        beta = bandpower(psd, freqs, 12, 30)\n",
        "        gamma = bandpower(psd, freqs, 30, 45)\n",
        "\n",
        "        # stack into (n_channels, 9) feature matrix\n",
        "        features = np.stack(\n",
        "            [mean_, var_, ptp_, zcr_, delta, theta, alpha, beta, gamma], axis=0\n",
        "        )\n",
        "        return features\n",
        "\n",
        "    def get(self, idx):\n",
        "        arr, meta = self.eeg_ds[idx]\n",
        "        if self.is_test:\n",
        "            signal_, sid = arr, meta\n",
        "            label = None\n",
        "        else:\n",
        "            signal_, label = arr, meta\n",
        "            sid = None\n",
        "\n",
        "        # signal: (n_time_bins, n_channels)\n",
        "        # features = self.extract_handcrafted_signal_features(signal_)\n",
        "        features = signal_\n",
        "        x = torch.tensor(features, dtype=torch.float)\n",
        "\n",
        "        y = torch.tensor([label], dtype=torch.long) if label is not None else None\n",
        "\n",
        "        data = Data(x=x, edge_index=self.edge_index, edge_attr=self.edge_weight, y=y)\n",
        "\n",
        "        # keep index for later id lookup\n",
        "        data.idx = torch.tensor([idx], dtype=torch.long)\n",
        "        return data\n",
        "\n",
        "\n",
        "graph_tr = GraphFromEEG(dataset_tr, A, is_test=False)\n",
        "graph_te = GraphFromEEG(dataset_te, A, is_test=True)\n",
        "\n",
        "loader_tr = DataLoader(graph_tr, batch_size=batch_size, shuffle=True)\n",
        "loader_te = DataLoader(graph_te, batch_size=batch_size, shuffle=False)\n",
        "for sample in loader_tr:\n",
        "  print(sample.x.shape)\n",
        "  break\n",
        "\n",
        "print(f\"Graphified train size: {len(graph_tr)}, test size: {len(graph_te)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNqVVvubcXva"
      },
      "source": [
        "### DataLoader with balancing\n",
        "Instantiate `DataLoader` over our training graph dataset—using a `WeightedRandomSampler` to balance seizure vs. non‑seizure windows during training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yVRk0FJTsEwx"
      },
      "outputs": [],
      "source": [
        "# Balance the labels by giving more weight to the minority class\n",
        "# Difference in the number of samples per class: [10476, 2517]\n",
        "\n",
        "train_labels = [data.y.item() for data in graph_tr]\n",
        "counts = np.bincount(train_labels)\n",
        "weights = 1.0 / counts  # gives more weight to the minority class\n",
        "\n",
        "# sample‐wise weight vector\n",
        "sample_weights = np.array([weights[l] for l in train_labels])\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights, num_samples=len(sample_weights), replacement=True\n",
        ")\n",
        "\n",
        "# rebuild the train loader\n",
        "loader_tr = DataLoader(graph_tr, batch_size=batch_size, sampler=sampler, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfe9wvzCcoA7"
      },
      "source": [
        "### Model Definition & Training\n",
        "Builds the GCN model (`EEG_GCN`) with two graph‐convolution layers followed by global mean pooling and a linear layer for binary classification also trains the GCN over 20 epochs using cross‑entropy and prints train loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN_fTvPVs4Du",
        "outputId": "841927ed-13b8-4c02-e792-bfb28c3877a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: Train Loss = 0.6402, Train Acc = 0.7035, Train F1 = 0.6997\n",
            "Epoch 02: Train Loss = 0.5868, Train Acc = 0.7278, Train F1 = 0.7252\n",
            "Epoch 03: Train Loss = 0.5708, Train Acc = 0.7461, Train F1 = 0.7458\n",
            "Epoch 04: Train Loss = 0.5550, Train Acc = 0.7376, Train F1 = 0.7374\n",
            "Epoch 05: Train Loss = 0.5604, Train Acc = 0.7546, Train F1 = 0.7544\n",
            "Epoch 06: Train Loss = 0.5439, Train Acc = 0.7513, Train F1 = 0.7511\n",
            "Epoch 07: Train Loss = 0.5441, Train Acc = 0.7751, Train F1 = 0.7751\n",
            "Epoch 08: Train Loss = 0.5386, Train Acc = 0.7680, Train F1 = 0.7662\n",
            "Epoch 09: Train Loss = 0.5397, Train Acc = 0.7789, Train F1 = 0.7786\n",
            "Epoch 10: Train Loss = 0.5377, Train Acc = 0.7589, Train F1 = 0.7550\n",
            "Epoch 11: Train Loss = 0.5254, Train Acc = 0.7857, Train F1 = 0.7850\n",
            "Epoch 12: Train Loss = 0.5279, Train Acc = 0.7915, Train F1 = 0.7912\n",
            "Epoch 13: Train Loss = 0.5234, Train Acc = 0.7778, Train F1 = 0.7775\n",
            "Epoch 14: Train Loss = 0.5227, Train Acc = 0.7923, Train F1 = 0.7917\n",
            "Epoch 15: Train Loss = 0.5148, Train Acc = 0.7754, Train F1 = 0.7751\n",
            "Epoch 16: Train Loss = 0.5179, Train Acc = 0.7935, Train F1 = 0.7931\n",
            "Epoch 17: Train Loss = 0.5153, Train Acc = 0.7963, Train F1 = 0.7953\n",
            "Epoch 18: Train Loss = 0.5144, Train Acc = 0.7978, Train F1 = 0.7977\n",
            "Epoch 19: Train Loss = 0.5198, Train Acc = 0.8057, Train F1 = 0.8054\n",
            "Epoch 20: Train Loss = 0.5256, Train Acc = 0.8011, Train F1 = 0.8009\n"
          ]
        }
      ],
      "source": [
        "# Model & Training\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "class EEG_GCN(torch.nn.Module):\n",
        "    def __init__(self, in_feats=1, hid_feats=32, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_feats, hid_feats)\n",
        "        self.conv2 = GCNConv(hid_feats, hid_feats)\n",
        "        self.conv3 = GCNConv(hid_feats, hid_feats)\n",
        "        self.lin = torch.nn.Linear(hid_feats, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, ei, ew, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        x = F.relu(self.conv1(x, ei))\n",
        "        x = F.relu(self.conv2(x, ei))\n",
        "        x = F.relu(self.conv3(x, ei))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.lin(x)\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, opt, device):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        opt.zero_grad()\n",
        "        loss = F.cross_entropy(model(data), data.y.view(-1))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total += loss.item() * data.num_graphs\n",
        "    return total / len(loader.dataset)\n",
        "\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            preds = model(data).argmax(dim=1)\n",
        "            correct += (preds == data.y.view(-1)).sum().item()\n",
        "            total += data.num_graphs\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(data.y.view(-1).cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    return correct / total, f1\n",
        "\n",
        "\n",
        "# Train & Validation\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EEG_GCN(in_feats=19).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train_epoch(model, loader_tr, optimizer, device)\n",
        "    acc, f1 = evaluate(model, loader_tr, device)\n",
        "    print(f\"Epoch {epoch:02d}: Train Loss = {loss:.4f}, Train Acc = {acc:.4f}, Train F1 = {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQbJShrQcyO5"
      },
      "source": [
        "### Test Prediction & Submission  \n",
        "Run inference on the test loader, map each prediction back to the original window IDs and write out a Kaggle‐compatible CSV of `id,label` rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F78dsCARzdkP",
        "outputId": "1263a66d-23d5-42e8-a606-1e3696ff2e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved submission.csv with 3614 rows\n"
          ]
        }
      ],
      "source": [
        "## Test & Submission\n",
        "\n",
        "model.eval()\n",
        "all_idxs, all_preds = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in loader_te:\n",
        "        # batch.idx is a tensor of shape [batch_size] giving the original idx\n",
        "        all_idxs.extend(batch.idx.cpu().tolist())\n",
        "        batch = batch.to(device)\n",
        "        logits = model(batch)\n",
        "        preds = logits.argmax(dim=1).cpu().tolist()\n",
        "        all_preds.extend(preds)\n",
        "\n",
        "all_ids = clips_te.index.tolist()\n",
        "\n",
        "# check\n",
        "assert len(all_ids) == len(all_preds)\n",
        "\n",
        "# write submission\n",
        "submission = pd.DataFrame({\"id\": all_ids, \"label\": all_preds})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(f\"Saved submission.csv with {len(submission)} rows\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}